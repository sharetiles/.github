<p align="center">
  <a href="https://github.com/tileshq/">
    <img src="https://avatars.githubusercontent.com/u/210493283?s=400&u=2f11fffd96608dab3c5e471f0b2ca3d51b528103&v=4" alt="Tiles Logo" width="128" />
  </a>
</p>
<p align="center">
  Private memory finetuning across your devices for creators, thinkers, and builders.
</p>
            <p>
 We'd love to partner with early-stage companies to build together. Join us in the Tiles <a href="https://discord.gg/yp3xQbHT" className="underline" target="_blank" rel="noopener noreferrer">Discord</a> server. Subscribe to our blog <a href="https://blog.tiles.run/" className="underline" target="_blank" rel="noopener noreferrer">Neurons</a> for updates on on-device AI and personalization research.
</p>

# Resources
Below is a living index of resources that inform and inspire our work.

## Engineering
- ‚ú® [Modelfile Reference - Ollama English Documentation](https://ollama.readthedocs.io/en/modelfile/)
- ‚ú® [Introducing Gemma 3n: The developer guide](https://developers.googleblog.com/en/introducing-gemma-3n-developer-guide/)
- ‚ú® [Foundation Models adapter training - Apple Intelligence - Apple Developer](https://developer.apple.com/apple-intelligence/foundation-models-adapter/)
- ‚ú® [Use MergeKit to Extract LoRA Adapters from any Fine-Tuned Model](https://www.arcee.ai/blog/use-mergekit-to-extract-lora-adapters-from-any-fine-tuned-model)
- ‚ú® [Apple‚Äôs New Containerization Framework: A Deep Dive into macOS‚Äôs Future for Developers](https://chamodshehanka.medium.com/apples-new-containerization-framework-a-deep-dive-into-macos-s-future-for-developers-cf102643394a)
- ‚ú® [LM Studio 0.3.4 ships with Apple MLX](https://lmstudio.ai/blog/lmstudio-v0.3.4)
- [MLX-VLM is a package for inference and fine-tuning of Vision Language Models (VLMs) on your Mac using MLX.](https://github.com/Blaizzy/mlx-vlm)
- ‚ú® [Optimizing AI Inference at Character.AI](https://research.character.ai/optimizing-inference/)
- ‚ú® [Optimizing AI Inference at Character.AI (Part Deux)](https://research.character.ai/optimizing-ai-inference-at-character-ai-part-deux/)
- ‚ú® [PrimeIntellect-ai/prime-iroh: Asynchronous P2P communication backend for decentralized pipeline parallelism](https://github.com/PrimeIntellect-ai/prime-iroh)
- ‚ú® [Introducing Gemma 3 270M: The compact model for hyper-efficient AI](https://developers.googleblog.com/en/introducing-gemma-3-270m/)
- ‚ú® [Unternet Kernel](https://github.com/unternet-co/client/tree/main/kernel)
- ‚ú® [SwiftWasm, WebAssembly support for the Swift programming language](https://github.com/swiftwasm/swift)
- [DSPy Notebook, The pretty much "official" DSPy framework for Typescript](https://github.com/ax-llm/ax)
- [Structured outputs for LLMs](https://github.com/dottxt-ai/outlines)
- [Accelerated PyTorch training on Mac](https://docs.pytorch.org/docs/stable/notes/mps.html)
- ‚ú® [Unsloth AI - Open Source Fine-tuning & RL for LLMs](https://unsloth.ai/)
- ‚ú® [Introducing LFM2: The Fastest On-Device Foundation Models on the Market](https://www.liquid.ai/blog/liquid-foundation-models-v2-our-second-series-of-generative-ai-models)
- ‚ú® [Mistral.rs, a cross-platform, highly-multimodal inference engine](https://github.com/EricLBuehler/mistral.rs)
- [Osmosis, Unlocking AI self-improvement at production scale](https://osmosis.ai/)
- [Supermemory MCP](https://mcp.supermemory.ai/)
- ‚ú® [Introducing the v0 composite model family, Vercel](https://vercel.com/blog/v0-composite-model-family#why-does-v0-need-a-composite-model-architecture?)
- [Agent Reinforcement Trainer, OpenPipe](https://github.com/openpipe/art)
- [Universal Quantized File Format: UQFF](https://github.com/EricLBuehler/mistral.rs/blob/master/docs/UQFF.md)
- [GGUF Tool Suite](https://github.com/Thireus/GGUF-Tool-Suite/)
- [uqff_maker](https://github.com/EricLBuehler/uqff_maker)
- [Minions, Big & Small LLMs working together](https://github.com/HazyResearch/minions)
- ‚ú® [The Kaitchup Index: A Leaderboard for Quantized LLMs](https://kaitchup.substack.com/p/the-kaitchup-index)
- [Pipecat Cloud: Enterprise Voice Agents Built On Open Source - Kwindla Hultman Kramer, Daily](https://www.youtube.com/watch?v=IA4lZjh9sTs)
- [Serving Voice AI at $1/hr: Open-source, LoRAs, Latency, Load Balancing - Neil Dwyer, Gabber](https://www.youtube.com/watch?v=rD23-VZZHOo)
- [üìèRULER: Easy Mode for RL Rewards](https://openpipe.ai/blog/ruler)
- [ART¬∑E: How We Built an Email Research Agent That Beats o3](https://openpipe.ai/blog/art-e-mail-agent)
- [OpenBench, Provider-agnostic, open-source evaluation infrastructure for language models](https://github.com/groq/openbench)
- ‚ú® [LoRA's Limitations: Head-to-Head with Full RL](https://osmosis.ai/blog/lora-comparison)
- [A DSPy rewrite to Rust](https://github.com/krypticmouse/DSRs)
- ‚ú® [A case for client-side machine learning, Christopher Fleetwood](https://www.are.na/block/37127633)
- ‚ú® [Ratchet Architecture](https://github.com/huggingface/ratchet/blob/master/ARCHITECTURE.md)
- ‚ú® [How Tailscale works](https://tailscale.com/blog/how-tailscale-works)
- [Democratizing Al: The Psyche Network Architecture, Nous Research](https://nousresearch.com/nous-psyche/)
- [Interoperability: Swift‚Äôs Super Power, Speaking in Swift by The Browser Company](https://speakinginswift.substack.com/p/interoperability-swifts-super-power)
- [HuJSON - "Human JSON" (JWCC)](https://github.com/tailscale/hujson)


## Research

- ‚ú® [The Bitter Lesson is coming for Tokenization](https://lucalp.dev/bitter-lesson-tokenization-and-blt/) 
- [On the Way to LLM Personalization: Learning to Remember User Conversations, Apple Machine Learning Research](https://machinelearning.apple.com/research/on-the-way)
- ‚ú® [Text-to-LoRA: Hypernetworks that adapt LLMs for specific benchmark tasks using only textual task description as the input ,Sakana AI](https://arxiv.org/abs/2506.06105)
- [How memory augmentation can improve large language models, IBM Research](https://research.ibm.com/blog/memory-augmented-LLMs)
- ‚ú® [Small Language Models are the Future of Agentic AI, NVIDIA Research](https://arxiv.org/abs/2506.02153)
- ‚ú® [Defeating Prompt Injections by Design, Google Deepmind](https://arxiv.org/abs/2503.18813)
- [LLM in a flash: Efficient Large Language Model Inference with Limited Memory](https://arxiv.org/abs/2312.11514)
- [Introducing FlexOlmo: a new paradigm for language model training and data collaboration, Allen AI](https://allenai.org/blog/flexolmo)
- [WhisperKit: On-device Real-time ASR with Billion-Scale Transformers, Argmax](https://openreview.net/attachment?id=6lC3MPFbVg&name=pdf)
- ‚ú® [Towards Large-scale Training on Apple Silicon, Exo Labs](https://openreview.net/pdf?id=TJjP8d5bms)
- [Kinetics: Rethinking Test-Time Scaling Laws](https://openreview.net/attachment?id=qxnJrm47Ag&name=pdf)
- [Enhancing Reasoning Capabilities of Small Language Models with Blueprints and Prompt Template Search](https://openreview.net/attachment?id=LsNstclw8Z&name=pdf)
- [LoFT: Low-Rank Adaptation That Behaves Like Full Fine-Tuning](https://arxiv.org/pdf/2505.21289)
- [AirLLM: Diffusion Policy-based Adaptive LoRA for Remote Fine-Tuning of LLM over the Air](https://arxiv.org/abs/2507.11515)
- [Comparative Analysis of Retrieval Systems in the Real World](https://arxiv.org/pdf/2405.02048)
- [FedVLM: Scalable Personalized Vision-Language Models through Federated Learning](https://arxiv.org/abs/2507.17088)
- [On the Way to LLM Personalization: Learning to Remember User Conversations](https://arxiv.org/abs/2411.13405)
- [A Preliminary Report On Edge-Verified Machine Learning, Exo Labs](https://github.com/exo-explore/evML/blob/main/A_Preliminary_Report_On_evML.pdf)
- ‚ú® [Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities](https://arxiv.org/abs/2408.07666)
- ‚ú® [Intent-Based Architecture and Their Risks](https://www.paradigm.xyz/2023/06/intents)
- [Your LLM Knows the Future: Uncovering Its Multi-Token Prediction Potential](https://arxiv.org/abs/2507.11851)
- [Cephalo: Multi-Modal Vision-Language Models for Bio-Inspired Materials Analysis and Design](https://arxiv.org/abs/2405.19076)


## Product

- [Environments Hub: A Community Hub To Scale RL To Open AGI, Prime Intellect](https://www.primeintellect.ai/blog/environments)
- ‚ú® [SYNTHETIC-1: Scaling Distributed Synthetic Data Generation for Verified Reasoning, Prime Intellect](https://www.primeintellect.ai/blog/synthetic-1)
- [SYNTHETIC-2 Release: Four Million Collaboratively Generated Reasoning Traces, Prime Intellect](https://www.primeintellect.ai/blog/synthetic-2-release)
- ‚ú® [USB Club. A social file exchange. For designers, artists, DJs, writers, musicians, researchers, engineers.](https://usb.club/)
- [Model Evaluation, Amp](https://ampcode.com/news/model-evaluation)
- ‚ú® [WWDC25: Apple‚Äôs Playing a Different Game](https://creativestrategies.com/wwdc25-apples-playing-a-different-game/)
- [Programming as theory building](https://pages.cs.wisc.edu/~remzi/Naur.pdf)
- ‚ú® [The Use of Knowledge in (AGI) Society, Luke Drago](https://lukedrago.substack.com/cp/160938645)
- ‚ú® [Workshop Labs Mission, Workshop Labs](https://workshoplabs.ai/)
- ‚ú® [Nature's many attempts to evolve a Nostr, Gordon Brander](https://newsletter.squishy.computer/p/natures-many-attempts-to-evolve-a)
- ‚ú® [Systems design explains the world: volume 1](https://apenwarr.ca/log/20201227)
- ‚ú® [Empowering humans in the age of AI, Imbue](https://imbue.com/company/vision/)
- ‚ú® [Everything is ugly, so go build something that isn't ‚Äî Raiza Martin, Huxe (ex NotebookLM)](https://www.youtube.com/watch?v=yG5d5UaGz1M)
- ‚ú® [Responsive Software, Osmosis](https://osmosis.ai/blog/responsive-software)
- ‚ú® [Designing algorithm-friendly interfaces](https://uxdesign.cc/designing-algorithm-friendly-interfaces-84da3ed076a9)
- ‚ú® [Why Tool Als Want to Be Agent Als, Gwern](https://gwern.net/tool-ai)
- [Agents vs Workflows: Why Not Both? ‚Äî Sam Bhagwat, Mastra.ai](https://www.latent.space/p/oai-v-langgraph)
- ‚ú® [Machines of Buying and Selling Grace - Adam Behrens, New Generation](https://www.youtube.com/watch?v=zlZz0mDF2eg)
- ‚ú® [Andrej Karpathy: Software Is Changing (Again)](https://www.youtube.com/watch?v=LCEmiRjPEtQ&t=2211s)
- ‚ú® [I Remastered Facebook's Little Red Book](https://spaccapeli.com/i-remastered-facebooks-little-red-book)
- ‚ú® [The Rise of Personal LLM "Cognitive Core", Andrej Karpathy](https://x.com/karpathy/status/1938626382248149433)
- [Why I hope Apple keeps investing in on-device AI](https://www.computerworld.com/article/4016798/why-i-hope-apple-keeps-investing-in-on-device-ai.html)
- [Fun stories from building OpenRouter and where all this is going - Alex Atallah, OpenRouter](https://www.youtube.com/watch?v=84Vtz2IL1Ug)
- [Arcee AI Conductor](https://models.arcee.ai/)
- ‚ú® [Announcing the Arcee Model Engine Public Beta](https://www.arcee.ai/blog/announcing-the-arcee-model-engine-public-beta)
- [Inference by Sequoia](https://inferencebysequoia.substack.com/about)
- ‚ú® [Something Pretty Right: A History of Visual Basic | Retool](https://retool.com/visual-basic)
- [Tailscale‚Äôs visual policy editor is in beta](https://tailscale.com/blog/visual-editor-beta)
- [FoundationDB: from idea to Apple acquisition](https://www.youtube.com/watch?v=C1nZzQqcPZw)

## Reference 
- ‚ú® [Planetary-Scale Inference: Previewing our Peer-To-Peer Decentralized Inference Stack](https://www.primeintellect.ai/blog/inference)
- [How to Scale Your Model](https://jax-ml.github.io/scaling-book/)
- [Deep (Learning) Focus, a blog on AI research concepts by Cameron R. Wolfe](https://cameronrwolfe.substack.com/)
- ‚ú® [r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/)
- ‚ú® [The State of On-Device LLMs](https://app.getcontrast.io/register/sota-the-state-of-llms)
- ‚ú® [lmstudio-community/gpt-oss-20b-MLX-8bit](https://huggingface.co/lmstudio-community/gpt-oss-20b-MLX-8bit)
- ‚ú® [lmstudio-community/gemma-3n-E4B-it-MLX-4bit](https://huggingface.co/lmstudio-community/gemma-3n-E4B-it-MLX-4bit)
- ‚ú® [The Power of Efficiency: Edge Al‚Äôs Role in Sustainable Generative Al Adoption](https://creativestrategies.com/research/gen-ai-edge-testing/)
- ‚ú® [An Analogy for Understanding Transformers](https://www.lesswrong.com/posts/euam65XjigaCJQkcN/an-analogy-for-understanding-transformers)
- ‚ú® [Neural networks, 3Blue1Brown](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
- [MCP 201: The power of protocol, Anthropic](https://www.youtube.com/watch?v=HNzH5Us1Rvg)
- [GGUF Quantization Docs (Unofficial)](https://github.com/iuliaturc/gguf-docs)
- [Reverse-engineering GGUF | Post-Training Quantization](https://www.youtube.com/watch?v=vW30o4U9BFE)
- [Reference implementation of the Transformer architecture optimized for Apple Neural Engine](https://github.com/apple/ml-ane-transformers)
- [H100 PCIe vs SXM vs NVL: Which H100 GPU Is Fastest and Most Cost-Effective for Fine-Tuning LLMs?](https://kaitchup.substack.com/p/h100-pcie-vs-sxm-vs-nvl-best-single)
- ‚ú® [Stanford CS25: V5 I Transformers in Diffusion Models for Image Generation and Beyond](https://www.youtube.com/watch?v=vXtapCFctTI)
- [WebAssembly and its platform targets](https://snarky.ca/webassembly-and-its-platform-targets/)
- [Apple Developer, Technotes, Learn about specific development topics through these in-depth technical articles.](https://developer.apple.com/documentation/technotes/)
- [The Apple Wiki](https://theapplewiki.com/wiki/Main_Page)
- [LLMs on a Budget](https://benjaminmarie.gumroad.com/l/llms-on-a-budget)
- [Mergekit founder explains model merging](https://www.youtube.com/watch?v=IVDNhQIzyIY)

-------
Copyright ¬© 2025, Tiles. All rights reserved.
